<!DOCTYPE html>
<html  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>盡量白話的Diffusion Model基礎知識整理</title>
        <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
        <link rel="apple-touch-icon-precomposed" href="images/apple-touch-icon.png">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/uikit/2.26.4/css/uikit.gradient.css">

        <!-- <link rel="stylesheet" href="style.css"> -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <!-- <script src="uikit.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/uikit.js"></script>
        <!-- <script src="scripts.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/scripts.js"></script>
        <!-- <script src="jquery.sticky-kit.js "></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                        <title>盡量白話的Diffusion Model基礎知識整理</title>
        <style type="text/css">code{white-space: pre;}</style>
                                <link rel="stylesheet" href="style.css" />
                                          <script
                                          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
                                          type="text/javascript"></script>
                               
    </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

                        <div class="uk-grid" data-uk-grid-margin>
                <div class="uk-width-1-1">
                    <h1 class="uk-heading-large">盡量白話的Diffusion
Model基礎知識整理</h1>
                                                        </div>
            </div>
            
            <div class="uk-grid" data-uk-grid-margin >          
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul>
                                                        <li><a
                                                        href="#denoising-diffusion-probabilistic-models-ddpm"
                                                        id="toc-denoising-diffusion-probabilistic-models-ddpm">Denoising
                                                        Diffusion
                                                        Probabilistic
                                                        Models
                                                        (DDPM)</a>
                                                        <ul>
                                                        <li><a
                                                        href="#forward-diffusion"
                                                        id="toc-forward-diffusion"><strong>Forward
                                                        Diffusion</strong></a></li>
                                                        <li><a
                                                        href="#reverse-diffusion"
                                                        id="toc-reverse-diffusion"><strong>Reverse
                                                        Diffusion</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#reference"
                                                        id="toc-reference">Reference</a></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">

                    
<p>整理給自己看的Diffusion Model基本知識<br />
為了方便理解寫得很白話(不負責任版)<br />
更新日期: 2024/10/22</p>
<h2 id="denoising-diffusion-probabilistic-models-ddpm">Denoising
Diffusion Probabilistic Models (DDPM)</h2>
<p>主要源自<a href="https://arxiv.org/abs/2006.11239">Denoising
Diffusion Probabilistic Models(2020)</a></p>
<p>一般我們可以假設人眼認為合理的影像應該會滿足某種特定的分布，用數學來表達就是一張真實圖像
<span class="math inline">\(\mathbf{x}_0\)</span> 需要滿足 <span
class="math inline">\(\mathbf{x}_0 \sim q(\mathbf{x})\)</span>
這個分布（這邊的<span
class="math inline">\(\mathbf{x}_0\)</span>不見得一定要是圖像，你想像得出來任何適用以上假設的case都可以）。當然想也知道像圖像這類複雜的分布是很難人為的用任何已知的數學形式去表達出來的，所以有人想到是不是可以用深度學習來模擬這樣的分布，藉此幫助我們做圖像生成。如果粗淺的理解，擴散這個概念就是不管你的初始狀態
<span class="math inline">\(\mathbf{x}_0\)</span>
長怎麼樣，反正經過長時間的擴散，各種不同的 <span
class="math inline">\(\mathbf{x}_0\)</span>
他們原始的特徵都會被稀釋掉、分布上也變得趨近一致。所以如果神經網路能逆轉這個擴散行為，用大量的擴散數據去學習反擴散的可能性，是不是就可以反過來從擴散的盡頭推測出一個合理的
<span
class="math inline">\(\mathbf{x}_0\)</span>？透過這個概念，以下的流程就被設計了出來，能夠對Diffusion為基礎的圖像生成模型進行訓練及採樣：</p>
<center>
<img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png" width="90%" alt="img01"/>
</center>
<p><br></p>
<h3 id="forward-diffusion"><strong>Forward Diffusion</strong></h3>
<p> 在<span class="math inline">\(\mathbf{x}_0 \sim
q(\mathbf{x})\)</span>這個前提下，如果對<span
class="math inline">\(\mathbf{x}_0\)</span>添加Gaussian noise，並重複
<span class="math inline">\(T\)</span> 次，生成出 <span
class="math inline">\(\mathbf{x}_1, ..., \mathbf{x}_T\)</span>
一系列的加噪圖像。在 <span class="math inline">\(T\)</span>
夠大的情況下，最後生成出來的<span
class="math inline">\(\mathbf{x}_T\)</span>應該會趨近於Gaussian
noise。以上操作數學上表示為：</p>
<p><span class="math display">\[\begin{aligned}
    q(\mathbf{x}_t|\mathbf{x}_{t-1})
    &amp;=\mathcal{N}(\mathbf{x}_t;\sqrt{1-\beta_t}\mathbf{x}_{t-1},\beta_t\mathbf{I})
\\
    &amp;=\sqrt{1-\beta_t}\mathbf{x}_{t-1}+\sqrt{\beta_t}\epsilon\qquad\epsilon\sim\mathcal{N}(0,
\mathbf{I})
    \end{aligned}\]</span></p>
<p> 其中，每一步加噪的Gaussian noise強度由 <span
class="math inline">\(\{ \beta_t \in (0, 1) \}_{t=0}^{T}\)</span>
控制，<span class="math inline">\(\beta_t\)</span> 會隨著 <span
class="math inline">\(T\)</span> 的上升也跟這越來越大，另外 <span
class="math inline">\(\beta_t\)</span>
也有很多種不同的schedule設計，包含linear、quadratic、cosine等等，會影響在
<span class="math inline">\(T\)</span>
個時間步階中圖像被加噪或去噪的趨勢。</p>
<p> 以上這個計算過程有一個好處，就是要得出 <span
class="math inline">\(\mathbf{x}_t\)</span>
時，不需要真的把中間過程的每一張圖都算出來，而是可以透過reparameterize的方式簡化（<font color=#800000><strong>對計算過程沒興趣可以直接跳到下個紅字</strong></font>）：</p>
<p>令<span class="math inline">\(\alpha_t=1-\beta_t\)</span> 且 <span
class="math inline">\(\bar{\alpha}_t=\prod_{i=1}^t \alpha_i\)</span></p>
<p><span class="math display">\[\begin{aligned}
\mathbf{x}_t
&amp;= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 -
\alpha_t}\boldsymbol{\epsilon}_{t-1}\quad\text{ ;where }
\boldsymbol{\epsilon}_{t-1}, \boldsymbol{\epsilon}_{t-2}, \dots \sim
\mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 -
\alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2}  \quad\text{
;where } \bar{\boldsymbol{\epsilon}}_{t-2} \text{ merges two Gaussians
(*).} \\
&amp;= \dots \\
&amp;= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 -
\bar{\alpha}_t}\boldsymbol{\epsilon} \\
q(\mathbf{x}_t \vert \mathbf{x}_0) &amp;= \mathcal{N}(\mathbf{x}_t;
\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})
\end{aligned}\]</span></p>
<p>這個簡化之所以可以成立是因為兩個分布的和是這樣計算的：</p>
<p><span class="math display">\[\mathcal{N}(\mathbf{0},
\sigma_1^2\mathbf{I})+\mathcal{N}(\mathbf{0},
\sigma_2^2\mathbf{I})=\mathcal{N}(\mathbf{0}, (\sigma_1^2 +
\sigma_2^2)\mathbf{I})\]</span></p>
<p>這使得 <span class="math inline">\(\epsilon\)</span>
項前面的係數（也就是標準差）能夠在推導的時候輕易的被合併。</p>
<p><span class="math display">\[\sqrt{(1 - \alpha_t) + \alpha_t
(1-\alpha_{t-1})} = \sqrt{1 - \alpha_t\alpha_{t-1}}\]</span></p>
<p> 這邊講了那麼多<font color=#800000><strong>其實結論就是，我們要在給定
<span class="math inline">\(\mathbf{x}_0\)</span> 時，求出 <span
class="math inline">\(\mathbf{x}_t\)</span>
只需要做一次以下的計算就夠了</strong></font>：</p>
<p><span class="math display">\[q(\mathbf{x}_t \vert
\mathbf{x}_0)=\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 -
\bar{\alpha}_t}\boldsymbol{\epsilon}\tag{1}\]</span></p>
<p>其中， <span class="math inline">\(\alpha_t=1-\beta_t\text{ ;
}\bar{\alpha}_t=\prod_{i=1}^t
\alpha_i\)</span>。我看到有些人之所以會誤會DDPM的訓練過程，以為訓練需要真的做數百次加噪的迭代，就是因為不清楚這個結論可以直接把迭代過程一步到位。</p>
<h3 id="reverse-diffusion"><strong>Reverse Diffusion</strong></h3>
<p> 如果我們可以逆轉上述流程，反過來用 <span
class="math inline">\(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\)</span>
去推測 <span
class="math inline">\(\mathbf{x}_{t-1}\)</span>，理論上就能夠從純粹的Gaussian
noise <span class="math inline">\(\mathbf{x}_T \sim
\mathcal{N}(\mathbf{0}, \mathbf{I})\)</span> 中一步步還原出真實圖像
<span class="math inline">\(\mathbf{x}_0 \sim
q(\mathbf{x})\)</span>。然而，人類很難用現有的數學知識解出 <span
class="math inline">\(q(\mathbf{x}_{t-1} \vert
\mathbf{x}_t)\)</span>。但是，如果我們先假設 <span
class="math inline">\(\mathbf{x}_t\)</span> 是從 <span
class="math inline">\(\mathbf{x}_0\)</span> 一路加噪過來的，考慮 <span
class="math inline">\(\mathbf{x}_0\)</span>
這個已知的條件後，式子就能改成：</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \vert \mathbf{x}_t,
\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1};
\tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})
\tag{2}\]</span></p>
<p>而且式中的均值 <span class="math inline">\(\tilde{\mu}_t\)</span>
和方差 <span class="math inline">\(\tilde{\beta}_t\)</span>
可以用貝氏定理去推導出解析解（就是跟國中學的一元二次公式解差不多的意思）：</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \vert \mathbf{x}_t,
\mathbf{x}_0)
= q(\mathbf{x}_t \vert \mathbf{x}_{t-1}, \mathbf{x}_0) \frac{
q(\mathbf{x}_{t-1} \vert \mathbf{x}_0) }{ q(\mathbf{x}_t \vert
\mathbf{x}_0) }\]</span></p>
<p>這邊透過貝氏定理就把Reverse的條件機率改成我們已知的形式了，可以直接找Forward
Diffusion中的一些結果代進去。跳過複雜的數學推導過程，總之可以得到的
<span class="math inline">\(\tilde{\mu}\)</span> 和 <span
class="math inline">\(\tilde{\beta}_t\)</span> 解析解：</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mu}_t (\mathbf{x}_t, \mathbf{x}_0)
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 -
\bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1
- \bar{\alpha}_t} \mathbf{x}_0\\
\tilde{\beta}_t
&amp;={\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t}
\end{aligned}\]</span></p>
<p>同時把公式(1)裡的的項調換一下，就可以得到 <span
class="math inline">\(\mathbf{x}_0 =
\frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 -
\bar{\alpha}_t}\boldsymbol{\epsilon}_t)\)</span> 代入 <span
class="math inline">\(\tilde{\mu}_t\)</span> 中，得到：</p>
<p><span class="math display">\[\tilde{\mu}_t =
\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 -
\alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t
\Big)\]</span></p>
<p> 解到這邊可以發現，除了 <span
class="math inline">\(\epsilon_t\)</span>
之外，其他的參數都是已知的（能透過Forward Diffusion中人為設定的 <span
class="math inline">\(\beta_t\)</span> 推算出來），最後我們就可以把求解
<span class="math inline">\(\epsilon_t\)</span>
這個重責大任丟給神經網路處理了。所以，<font color=#800000><strong>Reverse
Diffusion的結論就是，我們要訓練一個神經網路 <span
class="math inline">\(p_\theta\)</span> 來預測 <span
class="math inline">\(\epsilon_t\)</span>
，來解出公式(2)中的分布的均值與方差，如此一來便可以採樣出 <span
class="math inline">\(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\)</span>
的結果了</strong></font>。</p>
<p>寫累了，有空再補充</p>
<h2 id="reference">Reference</h2>
<ol type="1">
<li><a
href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What
are Diffusion Models?</a> (這篇很細，數學推導過程很完整)<br />
</li>
<li><a
href="https://yinglinzheng.netlify.app/diffusion-model-tutorial/">Diffusion
Models：生成扩散模型</a> (簡中的，寫的也還行)</li>
</ol>                    
                </div>
            </div>
            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
